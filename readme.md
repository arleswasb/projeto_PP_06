Com base na apresenta√ß√£o e nos c√≥digos do **Projeto 06 (Estimativa de œÄ)**, aqui est√° um arquivo `README.md` completo e formatado para o seu reposit√≥rio Git.

-----

# Estimativa de œÄ com OpenMP

> [cite\_start]Um Estudo sobre Sincroniza√ß√£o e Gerenciamento de Escopo de Vari√°veis [cite: 416]

[cite\_start]**Autor:** Werbert Arles de Souza Barradas [cite: 417]  
[cite\_start]**Disciplina:** Programa√ß√£o Paralela - DCA3703 [cite: 418]  
[cite\_start]**Institui√ß√£o:** Universidade Federal do Rio Grande do Norte (UFRN) [cite: 418]  
[cite\_start]**Data:** 31 de agosto de 2025 [cite: 419]

-----

## üìù Sobre o Projeto

[cite\_start]Este projeto explora a paraleliza√ß√£o da estimativa do valor de $\\pi$ utilizando o m√©todo de Monte Carlo, uma tarefa computacionalmente intensiva e ideal para testar os limites do paralelismo[cite: 424]. [cite\_start]O objetivo √© analisar o ganho de desempenho (speedup), demonstrar experimentalmente o problema da **condi√ß√£o de corrida** e explorar diferentes solu√ß√µes de sincroniza√ß√£o e gerenciamento de escopo de vari√°veis com a API OpenMP[cite: 426].

## ‚öôÔ∏è Vers√µes Implementadas

[cite\_start]O c√≥digo evolui atrav√©s de quatro abordagens distintas para ilustrar os desafios e as solu√ß√µes na programa√ß√£o paralela[cite: 427]:

1.  [cite\_start]**Vers√£o Sequencial:** Uma implementa√ß√£o de thread √∫nica que serve como *baseline* para validar a corre√ß√£o dos resultados e medir o desempenho base[cite: 428, 429].
2.  [cite\_start]**Vers√£o Paralela Ing√™nua:** Uma primeira tentativa de paraleliza√ß√£o com `#pragma omp parallel for` que intencionalmente exp√µe o problema da condi√ß√£o de corrida[cite: 430], resultando em valores incorretos para $\\pi$.
3.  [cite\_start]**Vers√£o Paralela com `critical`:** Uma corre√ß√£o que resolve a condi√ß√£o de corrida utilizando uma se√ß√£o cr√≠tica[cite: 431]. [cite\_start]Esta vers√£o produz o resultado correto, mas demonstra o alto custo de desempenho da sincroniza√ß√£o excessiva[cite: 431].
4.  [cite\_start]**Vers√£o Paralela Otimizada:** A solu√ß√£o final e eficiente, que utiliza vari√°veis privadas para contagem local (padr√£o de redu√ß√£o manual) para alcan√ßar tanto a corre√ß√£o do resultado quanto um ganho de desempenho significativo[cite: 432].

## üî¨ Conceitos Chave Abordados

### Condi√ß√£o de Corrida: Por que a Vers√£o Ing√™nua Falha?

[cite\_start]A instru√ß√£o `pontos_no_circulo++` n√£o √© uma opera√ß√£o at√¥mica[cite: 546]. [cite\_start]Ela consiste em tr√™s passos: ler, incrementar e escrever o valor de volta na mem√≥ria[cite: 548, 549, 550]. [cite\_start]Quando m√∫ltiplas threads executam esses passos simultaneamente, uma pode sobrescrever o trabalho da outra, levando √† perda de incrementos e a um resultado final incorreto[cite: 557].

#### Cen√°rio de Conflito:

  * [cite\_start]Thread A l√™ `total` (ex: 100)[cite: 553].
  * [cite\_start]Thread B l√™ `total` (ainda 100)[cite: 554].
  * [cite\_start]Thread A escreve `101`[cite: 555].
  * [cite\_start]Thread B tamb√©m escreve `101`[cite: 556].

[cite\_start]**Resultado:** Dois pontos foram encontrados, mas o contador foi incrementado apenas uma vez[cite: 557].

### Estrat√©gias de Sincroniza√ß√£o e Escopo

  * [cite\_start]**`#pragma omp critical`**: Garante a corre√ß√£o ao permitir que apenas uma thread por vez modifique a vari√°vel compartilhada, mas cria um gargalo de performance[cite: 431].
  * [cite\_start]**Redu√ß√£o Manual**: A vers√£o otimizada utiliza uma vari√°vel privada (`pontos_no_circulo_local`) para que cada thread conte seus pontos de forma independente[cite: 432]. A soma final √© feita em uma se√ß√£o `critical` executada apenas uma vez por thread, minimizando o custo da sincroniza√ß√£o.
  * **Gerenciamento de Escopo**: O projeto tamb√©m explora o uso de cl√°usulas como `shared`, `private` e `default(none)` para gerenciar explicitamente como as vari√°veis s√£o tratadas pelas threads.

## üìä Resultados

A tabela abaixo resume os resultados obtidos ao executar o programa para estimar $\\pi$ com $10^8$ itera√ß√µes.

| Vers√£o | Tempo de Execu√ß√£o (s) |
| :--- | :--- |
| **Sequencial** | [cite\_start]1.069 [cite: 568] |
| **Paralela (Ing√™nua)** | [cite\_start]1.05 [cite: 569] |
| **Paralela (Cr√≠tica)** | [cite\_start]5.176 [cite: 573] |
| **Paralela (Otimizada)**| [cite\_start]**0.39** [cite: 574] |

### An√°lise de Desempenho (Speedup)

Comparando a vers√£o sequencial com a otimizada:
[cite\_start]$S = \\frac{T\_{sequencial}}{T\_{paralelo}} = \\frac{1.069s}{0.390s} \\approx 2.74$ [cite: 583]

[cite\_start]A paraleliza√ß√£o otimizada resultou em um programa **2.74 vezes mais r√°pido** que a vers√£o sequencial[cite: 584].

## üöÄ Como Compilar e Executar

#### Pr√©-requisitos

  - Um compilador C com suporte a OpenMP (por exemplo, **GCC**).

#### Compila√ß√£o

Abra um terminal na pasta do projeto e use os seguintes comandos para compilar cada uma das vers√µes:

```bash
# Vers√£o Sequencial
gcc -o prog_sequencial prog_sequencial.c -fopenmp -lm

# Vers√£o Paralela Ing√™nua
gcc -o prog_paralel_for prog_paralel_for.c -fopenmp -lm

# Vers√£o com Critical (Lenta)
gcc -o prog_paralel_for_critical prog_paralel_for_critical.c -fopenmp -lm

# Vers√£o Otimizada com vari√°vel private
gcc -o prog_paralel_for_critical_private prog_paralel_for_critical_private.c -fopenmp -lm
```

  * `-fopenmp`: **Flag essencial** que habilita a compila√ß√£o com as bibliotecas OpenMP.
  * `-lm`: Link para a biblioteca matem√°tica.

#### Execu√ß√£o

Ap√≥s a compila√ß√£o, execute qualquer uma das vers√µes com:

```bash
./<nome_do_executavel>
# Exemplo:
./prog_paralel_for_critical_private
```

## üìö Conclus√£o

[cite\_start]O experimento demonstrou o potencial de ganho de desempenho do OpenMP, com um speedup de 2.74x na vers√£o otimizada, e os riscos inerentes √† programa√ß√£o concorrente[cite: 593]. [cite\_start]A escolha da estrat√©gia de sincroniza√ß√£o mostrou-se crucial, pois o uso inadequado (`critical` dentro do la√ßo) pode degradar a performance, enquanto a abordagem correta (redu√ß√£o manual) a otimiza[cite: 595]. [cite\_start]Compreender e aplicar mecanismos de sincroniza√ß√£o e gerenciamento de escopo √© fundamental para desenvolver software paralelo que seja n√£o apenas r√°pido, mas tamb√©m correto[cite: 597].